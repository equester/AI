{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled58.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5xE4raWngf6Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":276},"outputId":"540dd28f-3d1d-4774-851b-be64fed61189","executionInfo":{"status":"ok","timestamp":1560423840751,"user_tz":-330,"elapsed":10328,"user":{"displayName":"Lavi Nigam","photoUrl":"https://lh6.googleusercontent.com/-VVDbL0W4k54/AAAAAAAAAAI/AAAAAAAAClE/dqqBdY5uP8E/s64/photo.jpg","userId":"01031927567449846531"}}},"source":["!pip install rake_nltk"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting rake_nltk\n","  Downloading https://files.pythonhosted.org/packages/8e/c4/b4ff57e541ac5624ad4b20b89c2bafd4e98f29fd83139f3a81858bdb3815/rake_nltk-1.0.4.tar.gz\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rake_nltk) (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->rake_nltk) (1.12.0)\n","Building wheels for collected packages: rake-nltk\n","  Building wheel for rake-nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/ef/92/fc/271b3709e71a96ffe934b27818946b795ac6b9b8ff8682483f\n","Successfully built rake-nltk\n","Installing collected packages: rake-nltk\n","Successfully installed rake-nltk-1.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dmNR2RAWfZl6","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from rake_nltk import Metric, Rake\n","from nltk.tree import Tree\n","from nltk.corpus import stopwords, wordnet\n","from nltk import word_tokenize\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","import string"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUZj1MECf5HR","colab_type":"code","colab":{}},"source":["data = pd.read_csv(\"testAPINew.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvf7L4XEhDcS","colab_type":"code","colab":{}},"source":["def get_stopword_lists():\n","    '''\n","    params: \n","          None\n","          \n","    returns:\n","          a. sw_with_custom : nltk stopwords extended with stopwords custom defined by me. \n","                              This will be used in text_preprocess() and RAKE algorithms\n","          \n","          b. sw_final: All stopwords including custom sw and punctuation marks.\n","                       This will be used in our Vectorizer.\n","    '''\n","    #make different stopwords lists which will be filtered out in text_preprocess() and which will be used for Rake\n","\n","    sw = stopwords.words(\"english\")\n","    \n","    #define some custom stopwords\n","    custom_sw = ['since', 'because', '\"',\"'\",\"-\",'...', '..','``', \"''\" ,':','*','**','***','****','*****','upon','would','should','could','can'\n","                 ,'has','bar','good','really','bad']\n","    sw_with_custom = sw.copy()\n","    sw_with_custom.extend(custom_sw)\n","    \n","    # punctuations are stopwords too\n","    sw_with_punc = sw.copy()\n","    sw_with_punc.extend(list(string.punctuation))\n","    sw_with_custom_punc = sw_with_custom.copy()\n","    sw_with_custom_punc.extend(sw_with_punc)\n","    sw_with_custom_punc = list(set(sw_with_custom_punc))\n","    \n","    # define list of words to remove from nltk defined stopword list. Excess words and negation words are removed.\n","    #to_remove_from_sw =['no', 'not', 'nor', 'so', 'too', 'very']\n","    #sw = list(set(sw)-set(to_remove_from_sw))\n","    \n","    #add titlecase versions of all stopwords\n","    sw_final = sw_with_custom_punc.copy()\n","    sw_final.extend(list(map(lambda x: x.title(), sw_with_custom_punc)))\n","    sw_final = list(set(sw_final))\n","    \n","    return sw_with_custom, sw_final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCe3Yl1qgJn2","colab_type":"code","colab":{}},"source":["def getRakeTopic(eachvalue):\n","  try:\n","    r = Rake(stopwords = sw_with_custom, ranking_metric=Metric.DEGREE_TO_FREQUENCY_RATIO, min_length=2,max_length=4, punctuations=[\"'\",'.','?',';','!','..','?!','!?',',','*,','**,','***,','****,','*****,']) # Uses stopwords for english from NLTK, and all puntuation characters.\n","    r.extract_keywords_from_text(eachvalue)\n","    return r.get_ranked_phrases()\n","  except TypeError:\n","    return []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LjbcN39gu98","colab_type":"code","colab":{}},"source":["global sw_with_custom\n","sw_with_custom,sw_final = get_stopword_lists()\n","data['Topic'] = data.reviewText.apply(getRakeTopic)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7mdDfYMJiXk9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"830b0027-fe21-4c01-e8a0-5669b29556ab","executionInfo":{"status":"ok","timestamp":1560425399809,"user_tz":-330,"elapsed":994,"user":{"displayName":"Lavi Nigam","photoUrl":"https://lh6.googleusercontent.com/-VVDbL0W4k54/AAAAAAAAAAI/AAAAAAAAClE/dqqBdY5uP8E/s64/photo.jpg","userId":"01031927567449846531"}}},"source":["data['Topic'][91]"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(4.0, 'expensive brand'), (4.0, 'bit stiff')]"]},"metadata":{"tags":[]},"execution_count":32}]}]}