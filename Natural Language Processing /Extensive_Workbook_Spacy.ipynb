{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extensive Workbook Spacy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/equester/AI/blob/master/Natural%20Language%20Processing%20/Extensive_Workbook_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4Z0NKgSzdAEn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This Notebook has been created while doing Spacy Official Course from https://course.spacy.io . The content is an copy of the course and some of the code samples and use-cases are mine to practise the cocnepts. \n",
        "\n",
        "The purpose of this notebook is to create single \"Basic to Advance\" implementation of everything that can be done in Spacy for NLP. This will include, basic structures of Spacy Programming and bunch of different use-cases that can be solved using it. \n",
        "\n",
        "\n",
        "More Reference Links to learn Spacy: "
      ]
    },
    {
      "metadata": {
        "id": "4QtUmMPjd5pR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Basic "
      ]
    },
    {
      "metadata": {
        "id": "4bJMX6qdao3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At the center of spaCy is the object containing the processing pipeline. We usually call this variable \"nlp\".\n",
        "\n",
        "For example, to create an English nlp object, you can import the English language class from spacy dot lang dot en and instantiate it. You can use the nlp object like a function to analyze text.\n",
        "\n",
        "It contains all the different components in the pipeline.\n",
        "\n",
        "It also includes language-specific rules used for tokenizing the text into words and punctuation. spaCy supports a variety of languages that are available in spacy dot lang."
      ]
    },
    {
      "metadata": {
        "id": "ifEu1qYIaaLm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the English language class\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create the nlp object\n",
        "nlp = English()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "766cesl4a3IE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When you process a text with the nlp object, spaCy creates a Doc object – short for \"document\". The Doc lets you access information about the text in a structured way, and no information is lost.\n",
        "\n",
        "The Doc behaves like a normal Python sequence by the way and lets you iterate over its tokens, or get a token by its index. But more on that later!"
      ]
    },
    {
      "metadata": {
        "id": "T5TRj6zma4Dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2bfcf1ca-68f9-44f1-c7eb-84e8c68812e0"
      },
      "cell_type": "code",
      "source": [
        "# Created by processing a string of text with the nlp object\n",
        "doc = nlp(\"Hi There, This is Lavi Nigam, Testing Spacy\")\n",
        "\n",
        "# Iterate over tokens in a Doc\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi\n",
            "There\n",
            ",\n",
            "This\n",
            "is\n",
            "Lavi\n",
            "Nigam\n",
            ",\n",
            "Testing\n",
            "Spacy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K3J06b8YbGQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://course.spacy.io/doc.png)"
      ]
    },
    {
      "metadata": {
        "id": "skaBsUpgbH4E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Token objects represent the tokens in a document – for example, a word or a punctuation character.\n",
        "\n",
        "To get a token at a specific position, you can index into the Doc.\n",
        "\n",
        "Token objects also provide various attributes that let you access more information about the tokens. For example, the dot text attribute returns the verbatim token text."
      ]
    },
    {
      "metadata": {
        "id": "gYeHRc-fbLrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a502f364-2246-44f6-b6a9-eb0271bfa057"
      },
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hello world!\")\n",
        "\n",
        "# Index into the Doc to get a single Token\n",
        "token = doc[1]\n",
        "\n",
        "# Get the token text via the .text attribute\n",
        "print(token.text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wZX0s6MCbvN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Span Object\n",
        "![alt text](https://course.spacy.io/doc_span.png)"
      ]
    },
    {
      "metadata": {
        "id": "bvOdIaIxb02o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A Span object is a slice of the document consisting of one or more tokens. It's only a view of the Doc and doesn't contain any data itself.\n",
        "\n",
        "To create a Span, you can use Python's slice notation. For example, 1 colon 3 will create a slice starting from the token at position 1, up to – but not including! – the token at position 3."
      ]
    },
    {
      "metadata": {
        "id": "Lbpm95xjb25B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4362acd4-6fd4-4f05-9c1b-9c01c13afa8c"
      },
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Hello world!\")\n",
        "\n",
        "# A slice from the Doc is a Span object\n",
        "span = doc[1:4]\n",
        "\n",
        "# Get the span text via the .text attribute\n",
        "print(span.text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "world!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Okk1EX71cMJr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Lexical Attributes**\n",
        "\n",
        "Here you can see some of the available token attributes:\n",
        "\n",
        "\"i\" is the index of the token within the parent document.\n",
        "\n",
        "\"text\" returns the token text.\n",
        "\n",
        "\"is alpha\", \"is punct\" and \"like num\" return boolean values indicating whether the token consists of alphanumeric characters, whether it's punctuation or whether it resembles a number. For example, a token \"10\" – one, zero – or the word \"ten\" – T, E, N.\n",
        "\n",
        "These attributes are also called lexical attributes: they refer to the entry in the vocabulary and don't depend on the token's context."
      ]
    },
    {
      "metadata": {
        "id": "h_womCkhcSER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dca6e072-d167-4086-d90e-ef0b00462e18"
      },
      "cell_type": "code",
      "source": [
        "doc = nlp(\"It costs $five and $ 10.\")\n",
        "print('Index:   ', [token.i for token in doc])\n",
        "print('Text:    ', [token.text for token in doc])\n",
        "\n",
        "print('is_alpha:', [token.is_alpha for token in doc])\n",
        "print('is_punct:', [token.is_punct for token in doc])\n",
        "print('like_num:', [token.like_num for token in doc])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index:    [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "Text:     ['It', 'costs', '$', 'five', 'and', '$', '10', '.']\n",
            "is_alpha: [True, True, False, True, True, False, False, False]\n",
            "is_punct: [False, False, False, False, False, False, False, True]\n",
            "like_num: [False, False, False, True, False, False, True, False]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}